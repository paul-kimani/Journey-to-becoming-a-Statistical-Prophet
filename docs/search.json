[
  {
    "objectID": "bayesian-divination.html",
    "href": "bayesian-divination.html",
    "title": "Bayesian Divination: Updating Beliefs with Data",
    "section": "",
    "text": "In Bayesian lore, we start with a hunch (prior) and let data refine it (posterior).\nBehold a simple coin-flip oracle using rstanarm.\n\n\nCode\n#knitr::opts_chunk$set(\n#   echo = true,\n#   message = TRUE,\n#   warning = TRUE\n#)\n#install.packages(\"rstanarm\")\nlibrary(rstanarm)\n\n# Simulated flips: 7 heads in 10 tosses\ndata &lt;- data.frame(y = c(rep(1,7), rep(0,3)))  # 1 = head\n\n# Divination model\nmodel &lt;- stan_glm(y ~ 1, family = binomial(link = \"logit\"), data = data)\n\n\n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 1:                0.011 seconds (Sampling)\nChain 1:                0.021 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 2:                0.012 seconds (Sampling)\nChain 2:                0.022 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 5e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 3:                0.01 seconds (Sampling)\nChain 3:                0.02 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 4:                0.011 seconds (Sampling)\nChain 4:                0.021 seconds (Total)\nChain 4: \n\n\nCode\n# Posterior summary\nprint(model)\n\n\nstan_glm\n family:       binomial [logit]\n formula:      y ~ 1\n observations: 10\n predictors:   1\n------\n            Median MAD_SD\n(Intercept) 0.9    0.7   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\nCode\nposterior_interval(model, prob = 0.95)\n\n\n                  2.5%    97.5%\n(Intercept) -0.4068751 2.308205"
  },
  {
    "objectID": "bayesian-divination.html#the-priors-whisper",
    "href": "bayesian-divination.html#the-priors-whisper",
    "title": "Bayesian Divination: Updating Beliefs with Data",
    "section": "",
    "text": "In Bayesian lore, we start with a hunch (prior) and let data refine it (posterior).\nBehold a simple coin-flip oracle using rstanarm.\n\n\nCode\n#knitr::opts_chunk$set(\n#   echo = true,\n#   message = TRUE,\n#   warning = TRUE\n#)\n#install.packages(\"rstanarm\")\nlibrary(rstanarm)\n\n# Simulated flips: 7 heads in 10 tosses\ndata &lt;- data.frame(y = c(rep(1,7), rep(0,3)))  # 1 = head\n\n# Divination model\nmodel &lt;- stan_glm(y ~ 1, family = binomial(link = \"logit\"), data = data)\n\n\n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 1:                0.011 seconds (Sampling)\nChain 1:                0.021 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 2:                0.012 seconds (Sampling)\nChain 2:                0.022 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 5e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 3:                0.01 seconds (Sampling)\nChain 3:                0.02 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 4:                0.011 seconds (Sampling)\nChain 4:                0.021 seconds (Total)\nChain 4: \n\n\nCode\n# Posterior summary\nprint(model)\n\n\nstan_glm\n family:       binomial [logit]\n formula:      y ~ 1\n observations: 10\n predictors:   1\n------\n            Median MAD_SD\n(Intercept) 0.9    0.7   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\n\nCode\nposterior_interval(model, prob = 0.95)\n\n\n                  2.5%    97.5%\n(Intercept) -0.4068751 2.308205"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Journey to becoming a Statistical Prophet",
    "section": "",
    "text": "In the vast chaos of data, lies the power to foresee. This site chronicles my odyssey from novice code-wrangler to oracle of odds—armed with R, simulations, and a healthy dose of humility.\nExpect: - Simulations: Monte Carlo rituals to summon distributions from the void. - Prophecies: Bayesian divinations and time-series auguries. - Reflections: Lessons etched in code and charts.\nStart with a humble oracle: Behold, 10,000 whispers from the normal distribution, revealing the bell’s eternal curve."
  },
  {
    "objectID": "index.html#greetings-seeker-of-patterns",
    "href": "index.html#greetings-seeker-of-patterns",
    "title": "Journey to becoming a Statistical Prophet",
    "section": "",
    "text": "In the vast chaos of data, lies the power to foresee. This site chronicles my odyssey from novice code-wrangler to oracle of odds—armed with R, simulations, and a healthy dose of humility.\nExpect: - Simulations: Monte Carlo rituals to summon distributions from the void. - Prophecies: Bayesian divinations and time-series auguries. - Reflections: Lessons etched in code and charts.\nStart with a humble oracle: Behold, 10,000 whispers from the normal distribution, revealing the bell’s eternal curve."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the Seeker",
    "section": "",
    "text": "I am Paul, a code-tinkering mortal on the quest to unravel data’s divine riddles. By day, I wrangle spreadsheets in the mortal coil of [your job/industry]; by night, I commune with R’s arcane arts—summoning simulations, divining distributions, and occasionally cursing at convergence warnings.\nThis digital sanctum? Born from a late-night epiphany: Statistics isn’t just numbers; it’s prophecy. From humble rnorm() incantations to full-blown Bayesian soothsaying, every post here charts my ascent. Inspired by prophets past (Tukey, Fisher) and code gurus (Hadley Wickham, foremost), I share the scrolls: raw code, reproducible rituals, and hard-won revelations.\nWhy share? To light torches for fellow seekers—whether you’re debugging your first GLM or forecasting apocalypses with ARIMA. No gatekeeping; just open-source enlightenment."
  },
  {
    "objectID": "about.html#who-wanders-this-path",
    "href": "about.html#who-wanders-this-path",
    "title": "About the Seeker",
    "section": "",
    "text": "I am Paul, a code-tinkering mortal on the quest to unravel data’s divine riddles. By day, I wrangle spreadsheets in the mortal coil of [your job/industry]; by night, I commune with R’s arcane arts—summoning simulations, divining distributions, and occasionally cursing at convergence warnings.\nThis digital sanctum? Born from a late-night epiphany: Statistics isn’t just numbers; it’s prophecy. From humble rnorm() incantations to full-blown Bayesian soothsaying, every post here charts my ascent. Inspired by prophets past (Tukey, Fisher) and code gurus (Hadley Wickham, foremost), I share the scrolls: raw code, reproducible rituals, and hard-won revelations.\nWhy share? To light torches for fellow seekers—whether you’re debugging your first GLM or forecasting apocalypses with ARIMA. No gatekeeping; just open-source enlightenment."
  },
  {
    "objectID": "simulations.html",
    "href": "simulations.html",
    "title": "Random Variable Simulations",
    "section": "",
    "text": "Behold 5000 uniforms—adjust “n” in code for your rituals (static snapshot here).\nlibrary(ggplot2) n_draws &lt;- 5000 # Fixed “slider” value—tweak and re-render! set.seed(123) uniforms &lt;- runif(n_draws, min = 0, max = 1) df &lt;- data.frame(x = uniforms)\nggplot(df, aes(x)) + geom_histogram(bins = 50, fill = “skyblue”, alpha = 0.7) + labs(title = paste(“Uniform Whispers:”, n_draws, “Draws”), x = “Value”, y = “Count”) + theme_minimal()"
  },
  {
    "objectID": "simulations.html#uniform-distribution",
    "href": "simulations.html#uniform-distribution",
    "title": "Random Variable Simulations",
    "section": "",
    "text": "Behold 5000 uniforms—adjust “n” in code for your rituals (static snapshot here).\nlibrary(ggplot2) n_draws &lt;- 5000 # Fixed “slider” value—tweak and re-render! set.seed(123) uniforms &lt;- runif(n_draws, min = 0, max = 1) df &lt;- data.frame(x = uniforms)\nggplot(df, aes(x)) + geom_histogram(bins = 50, fill = “skyblue”, alpha = 0.7) + labs(title = paste(“Uniform Whispers:”, n_draws, “Draws”), x = “Value”, y = “Count”) + theme_minimal()"
  }
]